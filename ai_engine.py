# ai_engine.py
# KrishiGPT - AI Agricultural Advisor Engine (Groq SDK + Redis persistence)

import os
import json
import time
import logging
import redis
from datetime import datetime, date
from dotenv import load_dotenv
from groq import Groq

# Simple crop stage rules (DAS = days after sowing)
# You can refine ranges later.
STAGE_RULES = {
    "cotton": [
        (0, 20, "‡§Ö‡§Ç‡§ï‡•Å‡§∞‡§£ / ‡§â‡§ó‡§µ‡§£"),
        (21, 45, "‡§µ‡§æ‡§¢‡•Ä‡§ö‡•Ä ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ"),
        (46, 80, "‡§´‡•Å‡§≤‡•ã‡§∞‡§æ / ‡§ö‡•å‡§ï‡§ü"),
        (81, 130, "‡§¨‡•â‡§≤ ‡§µ‡§ø‡§ï‡§æ‡§∏"),
        (131, 999, "‡§ï‡§æ‡§™‡§£‡•Ä ‡§ú‡§µ‡§≥")
    ],
    "tomato": [
        (0, 20, "‡§∞‡•ã‡§™‡§æ‡§Ç‡§ö‡•Ä ‡§µ‡§æ‡§¢ / ‡§∞‡•ã‡§™‡§µ‡§æ‡§ü‡§ø‡§ï‡§æ"),
        (21, 40, "‡§∞‡•ã‡§™‡§æ‡§Ç‡§ö‡•Ä ‡§µ‡§æ‡§¢ / ‡§´‡•Å‡§ü‡§µ‡•á"),
        (41, 70, "‡§´‡•Å‡§≤‡•ã‡§∞‡§æ"),
        (71, 110, "‡§´‡§≥ ‡§µ‡§ø‡§ï‡§æ‡§∏"),
        (111, 999, "‡§ï‡§æ‡§™‡§£‡•Ä ‡§ú‡§µ‡§≥")
    ],
    "onion": [
        (0, 25, "‡§Ö‡§Ç‡§ï‡•Å‡§∞‡§£ / ‡§∞‡•ã‡§™ ‡§µ‡§æ‡§¢"),
        (26, 50, "‡§µ‡§æ‡§¢‡•Ä‡§ö‡•Ä ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ"),
        (51, 80, "‡§ï‡§Ç‡§¶ ‡§µ‡§ø‡§ï‡§æ‡§∏"),
        (81, 999, "‡§ï‡§æ‡§™‡§£‡•Ä ‡§ú‡§µ‡§≥")
    ],
    "soybean": [
        (0, 15, "‡§Ö‡§Ç‡§ï‡•Å‡§∞‡§£ / ‡§â‡§ó‡§µ‡§£"),
        (16, 35, "‡§∂‡§æ‡§ï‡•Ä‡§Ø ‡§µ‡§æ‡§¢"),
        (36, 65, "‡§´‡•Å‡§≤‡•ã‡§∞‡§æ / ‡§´‡§≥‡§ß‡§æ‡§∞‡§£‡§æ"),
        (66, 999, "‡§∂‡•á‡§Ç‡§ó‡§æ ‡§≠‡§∞‡§£‡•á / ‡§ï‡§æ‡§™‡§£‡•Ä ‡§ú‡§µ‡§≥")
    ]
    # You can add more crops later.
}


def parse_date_str(date_str: str):
    """Try to parse sowing date from common formats."""
    if not date_str:
        return None
    date_str = date_str.strip()
    for fmt in ("%Y-%m-%d", "%d-%m-%Y", "%d/%m/%Y"):
        try:
            return datetime.strptime(date_str, fmt).date()
        except ValueError:
            continue
    return None


# Logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# Env
load_dotenv()


class KrishiGPT:
    """
    KrishiGPT - AI Agricultural Advisor for Indian Farmers
    Supports Hindi and Marathi languages
    """
    def __init__(self):
        print("üåæ Initializing KrishiGPT...")

        # ---- LLM client (Groq) ----
        api_key = os.getenv("GROQ_API_KEY")
        if not api_key:
            raise ValueError("GROQ_API_KEY not found in environment variables!")
        self.client = Groq(api_key=api_key)

        # Pick a working model (env override ‚Üí cached ‚Üí fallback list)
        self.model = self._find_working_model()
        print(f"‚úÖ Using model: {self.model}")

        # ---- Prompts & KB ----
        self.system_prompt = self._load_system_prompt()
        print("‚úÖ System prompt loaded")

        self.crop_data = self._load_crop_data()
        print(f"‚úÖ Crop database loaded ({len(self.crop_data.get('crops', {}))} crops)")

        # ---- Memory stores ----
        self.conversations = {}  # in-memory fallback

        # Redis (Render Key Value)
        self.redis = None
        self.kv_ready = False
        self.history_ttl = int(os.getenv("CONV_TTL_SECONDS", "604800"))  # 7 days
        redis_url = os.getenv("REDIS_URL")
        if redis_url:
            try:
                self.redis = redis.from_url(redis_url, decode_responses=True)
                self.redis.ping()
                self.kv_ready = True
                print("‚úÖ Redis connected")
            except Exception as e:
                print(f"‚ö†Ô∏è Redis not available: {e}")
                self.redis = None
                self.kv_ready = False

        # Mark AI ready after a quick ping
        self.ai_ready = True
        print("üöÄ KrishiGPT is ready!\n")

    # ---------------- Model selection ----------------
    def _find_working_model(self):
        # 1) Env override
        env_model = (os.getenv("LLM_MODEL") or "").strip()
        if env_model:
            try:
                self.client.chat.completions.create(
                    model=env_model, messages=[{"role": "user", "content": "test"}], max_tokens=5
                )
                return env_model
            except Exception as e:
                logger.warning(f"LLM_MODEL '{env_model}' failed: {e}. Falling back‚Ä¶")

        # 2) Cached previous (ephemeral file)
        if os.path.exists("working_model.txt"):
            try:
                with open("working_model.txt", "r") as f:
                    saved = f.read().strip()
                if saved:
                    self.client.chat.completions.create(
                        model=saved, messages=[{"role": "user", "content": "test"}], max_tokens=5
                    )
                    return saved
            except Exception:
                pass

        # 3) Fallback list
        models_to_try = [
            "llama3-70b-8192",
            "llama3-8b-8192",
            "mixtral-8x7b-32768",
        ]
        for model_name in models_to_try:
            try:
                self.client.chat.completions.create(
                    model=model_name, messages=[{"role": "user", "content": "test"}], max_tokens=5
                )
                with open("working_model.txt", "w") as f:
                    f.write(model_name)
                return model_name
            except Exception:
                continue
        raise RuntimeError("No working model found on Groq!")

    # ---------------- Data loading ----------------
    def _load_system_prompt(self):
        prompt_path = "prompts/system_prompt.txt"
        if os.path.exists(prompt_path):
            with open(prompt_path, "r", encoding="utf-8") as f:
                return f.read()
        return (
            "‡§§‡•Å‡§Æ KrishiGPT ‡§π‡•ã - ‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø ‡§ï‡§ø‡§∏‡§æ‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è AI ‡§ï‡•É‡§∑‡§ø ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞‡•§ "
            "‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§î‡§∞ ‡§Æ‡§∞‡§æ‡§†‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•ã‡•§ ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï, ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§, ‡§î‡§∞ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§∏‡§≤‡§æ‡§π ‡§¶‡•ã‡•§"
        )

    def _load_crop_data(self):
        data_path = "prompts/crop_data.json"
        if os.path.exists(data_path):
            with open(data_path, "r", encoding="utf-8") as f:
                return json.load(f)
        return {"crops": {}, "government_schemes": [], "emergency_contacts": {}}

    # ---------------- NLU helpers ----------------
    def _detect_crop(self, query):
        q = query.lower()
        for crop_key, crop_info in self.crop_data.get("crops", {}).items():
            for kw in crop_info.get("keywords", []):
                if kw.lower() in q:
                    return crop_key, crop_info
        return None, None

    def _detect_query_type(self, query):
        q = query.lower()
        disease_keywords = [
            "‡§∞‡•ã‡§ó","‡§¨‡•Ä‡§Æ‡§æ‡§∞‡•Ä","‡§ï‡•Ä‡§ü","‡§∏‡•Å‡§Ç‡§°‡•Ä","‡§Æ‡§ï‡•ç‡§ñ‡•Ä","‡§á‡§≤‡§æ‡§ú","‡§â‡§™‡§ö‡§æ‡§∞","‡§™‡•Ä‡§≤‡§æ","‡§™‡•Ä‡§≤‡•á","‡§∏‡•Ç‡§ñ",
            "‡§Æ‡•Å‡§∞‡§ù‡§æ","‡§ß‡§¨‡•ç‡§¨‡•á","‡§õ‡•á‡§¶","‡§∏‡§°‡§º","disease","pest","treatment","yellow","dry","rot",
            "‡§Ö‡§≥‡•Ä","‡§Æ‡§æ‡§∂‡•Ä","‡§ï‡§ø‡§°‡§æ"
        ]
        fertilizer_keywords = ["‡§ñ‡§æ‡§¶","‡¶â‡∞∞‡±ç‡∞µ‡¶∞‡§ï","fertilizer","‡§Ø‡•Ç‡§∞‡§ø‡§Ø‡§æ","dap","npk","‡§™‡•ã‡§∑‡§ï","nutrient","‡§ñ‡§§","‡§Æ‡§æ‡§§‡•ç‡§∞‡§æ","‡§ï‡§ø‡§§‡§®‡§æ"]
        scheme_keywords = ["‡§Ø‡•ã‡§ú‡§®‡§æ","scheme","‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä","government","‡§∏‡§¨‡•ç‡§∏‡§ø‡§°‡•Ä","pm-kisan","‡§¨‡•Ä‡§Æ‡§æ","kcc","‡§ï‡•ç‡§∞‡•á‡§°‡§ø‡§ü","loan"]
        irrigation_keywords = ["‡§∏‡§ø‡§Ç‡§ö‡§æ‡§à","‡§™‡§æ‡§®‡•Ä","water","irrigation","‡§°‡•ç‡§∞‡§ø‡§™","drip","‡§∏‡•ç‡§™‡•ç‡§∞‡§ø‡§Ç‡§ï‡§≤‡§∞"]

        if any(kw in q for kw in disease_keywords): return "disease"
        if any(kw in q for kw in fertilizer_keywords): return "fertilizer"
        if any(kw in q for kw in scheme_keywords): return "scheme"
        if any(kw in q for kw in irrigation_keywords): return "irrigation"
        return "general"

    def _get_relevant_context(self, query):
        parts = []
        crop_key, crop_info = self._detect_crop(query)
        qtype = self._detect_query_type(query)

        if crop_info:
            parts.append(f"\nüìå ‡§´‡§∏‡§≤ ({crop_info.get('name_hi', crop_key)}):")
            parts.append(f"   - ‡§Æ‡•å‡§∏‡§Æ: {crop_info.get('season', 'N/A')}")
            parts.append(f"   - ‡§™‡§æ‡§®‡•Ä: {crop_info.get('water_requirement', 'N/A')}")
            if qtype == "disease":
                parts.append("\nüî¨ ‡§Ü‡§Æ ‡§¨‡•Ä‡§Æ‡§æ‡§∞‡§ø‡§Ø‡§æ‡§Ç:")
                for disease in crop_info.get("common_diseases", [])[:3]:
                    parts.append(f"\n   {disease.get('name','')}:")
                    parts.append(f"   ‡§≤‡§ï‡•ç‡§∑‡§£: {disease.get('symptoms','N/A')}")
                    parts.append(f"   ‡§ï‡§æ‡§∞‡§£: {disease.get('causes','N/A')}")
                    parts.append(f"   ‡§â‡§™‡§ö‡§æ‡§∞:")
                    for treatment in disease.get("treatment", []):
                        parts.append(f"      ‚Ä¢ {treatment}")
                    if "cost_per_acre" in disease:
                        parts.append(f"   ‡§ñ‡§∞‡•ç‡§ö: ‚Çπ{disease['cost_per_acre']}/‡§è‡§ï‡§°‡§º")
            if qtype in ["fertilizer","general"]:
                parts.append("\nüåø ‡§ñ‡§æ‡§¶ ‡§Ö‡§®‡•Å‡§∏‡•Ç‡§ö‡•Ä:")
                for schedule in crop_info.get("fertilizer_schedule", []):
                    parts.append(f"   ‚Ä¢ {schedule.get('stage','')}: {schedule.get('fertilizer','')}")
                    if schedule.get('cost'):
                        parts.append(f"     ‡§ñ‡§∞‡•ç‡§ö: ‚Çπ{schedule['cost']}")

        if qtype == "scheme":
            parts.append("\nüìã ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Ç:")
            for scheme in self.crop_data.get("government_schemes", []):
                parts.append(f"\n   {scheme.get('name','')}:")
                parts.append(f"   ‡§≤‡§æ‡§≠: {scheme.get('benefit','N/A')}")
                parts.append(f"   ‡§™‡§æ‡§§‡•ç‡§∞‡§§‡§æ: {scheme.get('eligibility','N/A')}")
                parts.append(f"   ‡§Ü‡§µ‡•á‡§¶‡§®: {scheme.get('apply','N/A')}")
                if scheme.get('helpline'):
                    parts.append(f"   ‡§π‡•á‡§≤‡•ç‡§™‡§≤‡§æ‡§á‡§®: {scheme['helpline']}")

        return "\n".join(parts) if parts else ""

    # -------- Stage helper --------
    def _get_stage_info(self, crop_key: str, sowing_date_str: str):
        """
        Compute approximate crop stage based on sowing date and simple DAS rules.
        crop_key: internal crop key (e.g., "cotton", "tomato")
        sowing_date_str: string date, e.g. "2025-06-15" or "15-06-2025"
        """
        if not crop_key or not sowing_date_str:
            return None

        crop_key = str(crop_key).lower()
        rules = STAGE_RULES.get(crop_key)
        if not rules:
            return None

        sow_date = parse_date_str(sowing_date_str)
        if not sow_date:
            return None

        today = date.today()
        das = (today - sow_date).days
        if das < 0:
            return None

        stage_label = "‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ (‡§Ö‡§Ç‡§¶‡§æ‡§ú‡•á)"
        for start, end, label in rules:
            if start <= das <= end:
                stage_label = label
                break

        return {"crop": crop_key, "das": das, "label": stage_label}

    # ---------------- Redis helpers ----------------
    def _conv_key(self, user_id):
        return f"conv:{user_id}"

    def _get_history(self, user_id):
        if self.redis:
            try:
                s = self.redis.get(self._conv_key(user_id))
                return json.loads(s) if s else []
            except Exception as e:
                logger.warning(f"Redis get failed, falling back to memory: {e}")
                self.redis = None
                self.kv_ready = False
        return self.conversations.get(user_id, [])

    def _set_history(self, user_id, msgs):
        msgs = msgs[-20:]  # keep last 20
        if self.redis:
            try:
                self.redis.setex(self._conv_key(user_id), self.history_ttl, json.dumps(msgs))
                return
            except Exception as e:
                logger.warning(f"Redis set failed, falling back to memory: {e}")
                self.redis = None
                self.kv_ready = False
        self.conversations[user_id] = msgs
    def _clear_history(self, user_id):
        if self.redis:
            self.redis.delete(self._conv_key(user_id))
        else:
            self.conversations.pop(user_id, None)

    # ---------------- Public API ----------------
    def get_response(self, user_id, query, max_retries=3, meta=None):
        logger.info(f"User {user_id}: {query[:50]}...")
        history = self._get_history(user_id)

        # --- Stage text (optional) ---
        stage_text = ""
        if meta and isinstance(meta, dict):
            crop_key = meta.get("crop_key") or meta.get("crop")
            sowing_date = meta.get("sowing_date")
            stage_info = self._get_stage_info(crop_key, sowing_date)
            # fallback: detect crop from query if not provided
            if not stage_info and sowing_date:
                detected_crop, _ = self._detect_crop(query)
                if detected_crop:
                    stage_info = self._get_stage_info(detected_crop, sowing_date)
            if stage_info:
                stage_text = (
                    f"\n\n--- üå± ‡§´‡§∏‡§≤ ‡§ï‡•Ä ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ ---\n"
                    f"‡§∏‡§ß‡•ç‡§Ø‡§æ ‡§Ö‡§Ç‡§¶‡§æ‡§ú‡•á {stage_info['das']} ‡§¶‡§ø‡§µ‡§∏ ‡§ù‡§æ‡§≤‡•á ‡§Ü‡§π‡•á‡§§ (DAS). "
                    f"‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ: {stage_info['label']}."
                )

        crop_context = self._get_relevant_context(query)
        enhanced_prompt = self.system_prompt

        if stage_text:
            enhanced_prompt += stage_text

        if crop_context:
            enhanced_prompt += f"\n\n--- üìö ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä (Knowledge Base ‡§∏‡•á) ---\n{crop_context}"
            enhanced_prompt += "\n\n--- ‚ö†Ô∏è ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂ ---\n‡§ä‡§™‡§∞ ‡§¶‡•Ä ‡§ó‡§à ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§, ‡§µ‡•ç‡§Ø‡§æ‡§µ‡§π‡§æ‡§∞‡§ø‡§ï ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•ã‡•§"

        messages = [{"role": "system", "content": enhanced_prompt}]
        messages.extend(history[-20:])  # last 20 messages
        messages.append({"role": "user", "content": query})

        for attempt in range(max_retries):
            try:
                t0 = time.time()
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=1000,
                    top_p=0.9
                )
                dt = time.time() - t0
                logger.info(f"Response generated in {dt:.2f}s")

                ai_response = response.choices[0].message.content

                history.append({"role": "user", "content": query})
                history.append({"role": "assistant", "content": ai_response})
                self._set_history(user_id, history)

                return ai_response
            except Exception as e:
                logger.error(f"Attempt {attempt + 1} failed: {e}")
                if attempt < max_retries - 1:
                    time.sleep(1)
                else:
                    return ("‚ùå ‡§Æ‡§æ‡§´ ‡§ï‡§∞‡•á‡§Ç, ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§•‡•ã‡§°‡§º‡•Ä ‡§¶‡•á‡§∞ ‡§¨‡§æ‡§¶ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç‡•§ üôè\n"
                            "‡§Ö‡§ó‡§∞ ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§¨‡§®‡•Ä ‡§∞‡§π‡•á ‡§§‡•ã ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•â‡§≤ ‡§∏‡•á‡§Ç‡§ü‡§∞ ‡§™‡§∞ ‡§ï‡•â‡§≤ ‡§ï‡§∞‡•á‡§Ç: 1551")

    def _clear_history(self, user_id):
        if self.redis:
            try:
                self.redis.delete(self._conv_key(user_id))
                return
            except Exception as e:
                logger.warning(f"Redis delete failed, falling back to memory: {e}")
                self.redis = None
                self.kv_ready = False
        self.conversations.pop(user_id, None)

    def get_quick_info(self, topic):
        topic_lower = topic.lower()
        if "‡§Ø‡•ã‡§ú‡§®‡§æ" in topic_lower or "scheme" in topic_lower:
            schemes = self.crop_data.get("government_schemes", [])
            if schemes:
                result = "üìã **‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ‡§è‡§Ç:**\n\n"
                for scheme in schemes:
                    result += f"üîπ **{scheme.get('name', '')}**\n"
                    result += f"   {scheme.get('benefit', '')}\n"
                    result += f"   ‡§Ü‡§µ‡•á‡§¶‡§®: {scheme.get('apply', '')}\n\n"
                return result
        if "‡§π‡•á‡§≤‡•ç‡§™‡§≤‡§æ‡§á‡§®" in topic_lower or "helpline" in topic_lower or "‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï" in topic_lower:
            contacts = self.crop_data.get("emergency_contacts", {})
            if contacts:
                result = "üìû **‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§π‡•á‡§≤‡•ç‡§™‡§≤‡§æ‡§á‡§®:**\n\n"
                result += f"üåæ ‡§ï‡§ø‡§∏‡§æ‡§® ‡§ï‡•â‡§≤ ‡§∏‡•á‡§Ç‡§ü‡§∞: {contacts.get('kisan_call_center', 'N/A')}\n"
                result += f"üî¨ ‡§ï‡•É‡§∑‡§ø ‡§µ‡§ø‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞: {contacts.get('krishi_vigyan_kendra', 'N/A')}\n"
                result += f"üì± PM-KISAN ‡§π‡•á‡§≤‡•ç‡§™‡§≤‡§æ‡§á‡§®: {contacts.get('pm_kisan_helpline', 'N/A')}\n"
                return result
        return None


# Local test runner
if __name__ == "__main__":
    print("=" * 60)
    print("üåæ KrishiGPT - AI Agricultural Advisor")
    print("=" * 60)
    bot = KrishiGPT()

    # Optional: quick stage test
    meta_example = {"crop": "cotton", "sowing_date": "01-10-2025"}  # adjust date as needed

    qs = [
        "‡§ü‡§Æ‡§æ‡§ü‡§∞ ‡§ï‡•Ä ‡§™‡§§‡•ç‡§§‡§ø‡§Ø‡§æ‡§Ç ‡§™‡•Ä‡§≤‡•Ä ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡§Ç, ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡•Ç‡§Ç?",
        "‡§ï‡§™‡§æ‡§∏ ‡§Æ‡•á‡§Ç ‡§ó‡•Å‡§≤‡§æ‡§¨‡•Ä ‡§∏‡•Å‡§Ç‡§°‡•Ä ‡§ï‡§æ ‡§á‡§≤‡§æ‡§ú ‡§¨‡§§‡§æ‡§ì",
        "PM-KISAN ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡•ã",
        "‡§™‡•ç‡§Ø‡§æ‡§ú ‡§Æ‡•á‡§Ç ‡§•‡•ç‡§∞‡§ø‡§™‡•ç‡§∏ ‡§ï‡§æ ‡§â‡§™‡§ö‡§æ‡§∞",
        "‡§∏‡•ã‡§Ø‡§æ‡§¨‡•Ä‡§® ‡§Æ‡•á‡§Ç ‡§ï‡•å‡§® ‡§∏‡•Ä ‡§ñ‡§æ‡§¶ ‡§°‡§æ‡§≤‡•á‡§Ç?"
    ]
    for i, q in enumerate(qs, 1):
        print(f"\n[{i}] {q}")
        # pass meta only if you want stage info; otherwise just bot.get_response(..., q)
        print(bot.get_response(f"test_user_{i}", q, meta=meta_example if i == 2 else None))
        time.sleep(0.5)