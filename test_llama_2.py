# test_llama_2.py
# Second test - testing Marathi language and different query

import os
from dotenv import load_dotenv
from groq import Groq

load_dotenv()
client = Groq(api_key=os.getenv("GROQ_API_KEY"))

# Test 1: Marathi Query
print("üß™ Test 1: Marathi Language")
print("Question: ‡§ï‡§æ‡§™‡§∏‡§æ‡§µ‡§∞ ‡§ó‡•Å‡§≤‡§æ‡§¨‡•Ä ‡§¨‡•ã‡§Ç‡§° ‡§Ö‡§≥‡•Ä ‡§Ü‡§≤‡•Ä ‡§Ü‡§π‡•á, ‡§ï‡§æ‡§Ø ‡§ï‡§∞‡•Ç?")
print("-" * 50)

response1 = client.chat.completions.create(
    model="llama-3.3-70b-versatile",
    messages=[
        {
            "role": "system",
            "content": "You are an expert Indian agricultural advisor. Answer in Marathi. Keep response short."
        },
        {
            "role": "user",
            "content": "‡§ï‡§æ‡§™‡§∏‡§æ‡§µ‡§∞ ‡§ó‡•Å‡§≤‡§æ‡§¨‡•Ä ‡§¨‡•ã‡§Ç‡§° ‡§Ö‡§≥‡•Ä ‡§Ü‡§≤‡•Ä ‡§Ü‡§π‡•á, ‡§ï‡§æ‡§Ø ‡§ï‡§∞‡•Ç?"
        }
    ],
    temperature=0.7,
    max_tokens=400
)

print(response1.choices[0].message.content)
print("\n" + "=" * 50 + "\n")

# Test 2: Government Scheme Query
print("üß™ Test 2: Government Scheme Query")
print("Question: PM-KISAN ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§ì")
print("-" * 50)

response2 = client.chat.completions.create(
    model="llama-3.3-70b-versatile",
    messages=[
        {
            "role": "system",
            "content": "You are an expert on Indian government schemes for farmers. Answer in Hindi."
        },
        {
            "role": "user",
            "content": "PM-KISAN ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§§‡§æ‡§ì"
        }
    ],
    temperature=0.7,
    max_tokens=400
)

print(response2.choices[0].message.content)
print("\n" + "=" * 50)

print("\n‚úÖ Both tests completed successfully!")
print("Your Llama AI is ready for KrishiGPT!")